# Assignment 2: Pilot Usability Testing

## Elena Leon Guerrero - DH150 Fall 2020

### Introduction: Moodnotes App

Moodnotes is an app that allows its users to track their mood and journal their feelings. The app encourages the tracking of mood over time, in order to gain valuable insights about one's mental state (e.g. triggers, mental “traps”, etc.). By using this app, people are promised help with their mental health, such as by developing healthier thinking habits, increasing their self-awareness of their current state, and reducing anxiety and a sense of well-being.

### Purpose of the Usability Test

Following my heuristic review of the Moodnotes, I found several usability issues. The main ones being tested were as follows:

* *The app includes a feature that allows its users to scan their face in order to accelerate the mood tracking process. However, this feature is very finnicky, and has a tendency to not accurately capture a user’s face/expressions, which may prove to slow down rather than speed up the process. *(Heuristic: Match Between System and the Real World)**
* *Journal entries are a large part of this mood-tracking app, however, when inputting the text for a journal entry, the app fails to prevent users from making the mistake of erasing their entire response if they accidentally leave the entry while editing. Not only that, but there are some issues with external consistency and standards, as well as some user control, that make navigating journal entry a less fluid process (e.g. lack of alternative actions, users must push “save” even if they didn’t make any changes). *(Heuristics: User Control and Freedom, Error Prevention)**
* *The design of the app is decently aesthetic and minimalistic, however, there are various issues with readability and accessibility for users. Examples of this include hard-to-see buttons and sliders due to a lack of contrast in the color scheme, which may hinder users when navigating the product. *(Heuristic: Aesthetic and Minimalistic Design)**
* *Finally, while the app does include a help page, it is extremely hard to find. This can be very frustrating and discouraging to a user that needs help. Not only that, but even if the help page is found, the FAQ is somewhat lacking and not even in-app. *(Heuristic: Help and Documentation)**

The purpose of a usability test (UT) is to improve the usability of a product by seeing how everyday users would interact with it. Through this type of feedback, researchers are able to see specific pain points a user may have when utilizing a product, by observing their immediate thoughts and actions when trying to navigate its interface. Moreover, this feedback also allows researchers to see how effective, efficient, and satisfactory a product is from a user’s perspective when it comes to completing its intended use. 

As a result, I made three tasks for my participant to test for some of the usability issues found during my heuristic evaluation:

*1. Perform a facial recognition scan and add details with a journal entry.*

*2. Editing a journal entry*

*3. Navigate to the help page for assistance*

### Methodology
This usability test was a pilot test where I aimed to test the setting and materials of a UT. I was a moderator and recruited my boyfriend as the user. The usability test was performed in a quiet kitchen of an apartment though a portable minimalistic lab setting. This portable minimalistic lab contained the moderator’s personal laptop, the moderator’s cellular phone (screen-mirrored onto the laptop via Quicktime), and Google Form survey materials presented via the laptop. Additionally, the usability test was recorded through Zoom, where the screen with the app and survey materials, the video containing the participant and moderator, and the audio were all recorded. 

#### Process

The process for the usability test was as follows:
1. The participant was provided an introduction of the usability test to be performed, as well as a consent form to acknowledge and grant their participation.
2. Background questions assessing the participant’s (potential) prior interaction with the app were asked.
3. Pre-test questions assessing the participant’s initial impressions of the app were asked.
4. Following the pre-test questions, the participant conducted three tasks concerning various functions of the product.
5. After the three tasks, the participant answered a post-test questionnaire asking them to rate items such as how easy it was to complete a task, how much they agree/disagree with certain statements, etc.
6. The participant then filled out a product satisfaction card that assessed their feelings towards the product through various adjectives.
7. Finally, the participant answered a demographics questionnaire.

#### Measures
Examples of the variables being measured (on a 7-point Likert scale) were as follows:

* Ease of use
* Frequency of use
* Learn ability
* Efficiency
* Effectiveness
* Satisfaction
* Aesthetic Appeal


#### Links

* The usability materials can be found [here](https://forms.gle/ZtNzKPJSBfcMsj8fA). 
* The pilot usability test video can be found  [here](https://drive.google.com/drive/folders/17ShcCmdWYxJCs9IiQXQ6GUjcq7LQAz_v?usp=sharing).

### Reflection

After conducting the usability test, I feel like I learned a lot. I had not yet had a chance to be the moderator, so one thing I learned was that it was definitely hard to prevent myself from telling the user how to complete the task as he went through it -- much like my peers have said. Moreover, I found it interesting just how conscious I was of myself (e.g. body language, what I would say, how I would say it) as a moderator, as I was when I was a participant. Finally, one last thing I learned was that it felt as though some of the issues I saw in the app were not seen as such to an everyday user, which kind of made me question what really is an issue. 

What went well during the usability test was that the testing environment and all the technology used seemed to function correctly, despite the complicated setup I had when recording. Additionally, my user was very articulate about his thoughts, and kept speaking throughout the whole process which brought some usability issues to my attention that I didn’t even consider (e.g. unclear navigation, lack of erasing features). What went not so well was when my user didn’t quite use the facial recognition feature correctly, as he hadn’t yet let it zero before he attempted to use it. I feel like this caused an inaccurate representation of the feature, as it is usually more finicky than that, but since the mood it recorded without zero-ing out was the mood my user was going for, he readily accepted it. Something else that went not as well was when I had to figure out how to guide my user, especially when I noticed he hadn’t been paying enough attention to the instructions/straying from the task, since he would extract more from the directions than necessary. I found there to be a thin line between keeping the user on track, versus leading them in the right direction, but I did my best to stay neutral. As a result, one way I want to improve my usability testing in the future might be by rewording my materials, such that they’re clear and easier for the participant to grasp at face value. After all, it may have been my fault that my user ended up straying from the task due to inadequate/ambiguous directions. I would also like to get better at knowing when to intervene versus not, as I definitely felt like I could have been crossing the line. Finally, I think that I could have been more encouraging throughout the session, so I hope to improve on that too.


